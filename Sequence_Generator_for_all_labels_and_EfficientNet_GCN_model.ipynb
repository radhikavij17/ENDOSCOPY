{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_2FcXSRib-O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "def create_adjacency_matrix(sequence_length):\n",
        "    adjacency_matrix = np.eye(sequence_length, k=1) + np.eye(sequence_length, k=-1)\n",
        "    return adjacency_matrix\n",
        "\n",
        "#here the sequence generator is different because an adjacency matrix has to be created in order for the GCN model to find connections between nodes\n",
        "\n",
        "class SequentialDataGenerator(Sequence):\n",
        "    def __init__(self, X, Y_int, batch_size=16, num_classes=5, max_sequence_length=None):\n",
        "        self.X = X\n",
        "        self.Y_int = Y_int\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.max_sequence_length = max_sequence_length or self._max_length()\n",
        "        self.indexes = np.arange(len(self.X))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        batch_X = [self.X[k] for k in indexes]\n",
        "        batch_Y_int = [self.Y_int[k] for k in indexes]\n",
        "\n",
        "        X_temp_padded = self._pad_sequences(batch_X, self.max_sequence_length)\n",
        "\n",
        "        Y_temp_padded = self._process_labels(batch_Y_int)\n",
        "\n",
        "        batch_A = np.array([create_adjacency_matrix(self.max_sequence_length) for _ in range(len(indexes))])\n",
        "\n",
        "        return [np.array(X_temp_padded), batch_A], Y_temp_padded\n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "\n",
        "    def _max_length(self):\n",
        "        return max(len(seq) for seq in self.X)\n",
        "\n",
        "    def _pad_sequences(self, sequences, max_seq_length, pad_val=0):\n",
        "        padded_sequences = []\n",
        "        for seq in sequences:\n",
        "            seq = np.array(seq)\n",
        "            pad_size = max_seq_length - len(seq)\n",
        "\n",
        "            if pad_size > 0:\n",
        "                pad_shape = list(seq.shape)\n",
        "                pad_shape[0] = pad_size\n",
        "\n",
        "                pad_array = np.full(pad_shape, pad_val)\n",
        "\n",
        "                padded_seq = np.concatenate((seq, pad_array), axis=0)\n",
        "            else:\n",
        "                padded_seq = seq\n",
        "\n",
        "            padded_sequences.append(padded_seq)\n",
        "\n",
        "        return np.array(padded_sequences)\n",
        "\n",
        "    def _process_labels(self, labels):\n",
        "        Y_temp_padded = np.zeros((len(labels), self.max_sequence_length, self.max_sequence_length, self.num_classes))\n",
        "\n",
        "        for i, seq_labels in enumerate(labels):\n",
        "            one_hot_labels = to_categorical(seq_labels, num_classes=self.num_classes)\n",
        "            pad_len = self.max_sequence_length - len(one_hot_labels)\n",
        "            if pad_len > 0:\n",
        "                one_hot_labels = np.vstack((one_hot_labels, np.zeros((pad_len, self.num_classes))))\n",
        "\n",
        "\n",
        "            Y_temp_padded[i, :len(one_hot_labels), :len(one_hot_labels), :] = one_hot_labels\n",
        "\n",
        "        return Y_temp_padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CNJ4kUfmS8V"
      },
      "outputs": [],
      "source": [
        "num_classes = 5\n",
        "num_nodes = 16 #arbritary number of nodes\n",
        "\n",
        "\n",
        "train_generator = SequentialDataGenerator(X_train, Y_train_int, batch_size=16, num_classes=num_classes)\n",
        "\n",
        "validation_generator = SequentialDataGenerator(X_test, Y_test_int, batch_size=16, num_classes=num_classes)\n",
        "\n",
        "train_X, train_Y = next(iter(train_generator))\n",
        "print(\"Training batch X shape:\", train_X[0].shape)\n",
        "print(\"Training batch adjacency matrix shape:\", train_X[1].shape)\n",
        "print(\"Training batch Y shape:\", train_Y.shape)\n",
        "\n",
        "validation_X, validation_Y = next(iter(validation_generator))\n",
        "print(\"Validation batch X shape:\", validation_X[0].shape)\n",
        "print(\"Validation batch adjacency matrix shape:\", validation_X[1].shape)\n",
        "print(\"Validation batch Y shape:\", validation_Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0NaPJbnxCBq"
      },
      "outputs": [],
      "source": [
        "pip install spektral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X8ERAv5tqQW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TimeDistributed, Dense, Flatten, Dropout, Layer, Input, Reshape, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers, models\n",
        "from spektral.layers import GCNConv\n",
        "\n",
        "def create_sequence_model(sequence_length, num_nodes, num_features, num_classes, dropout_rate=0.25, l2_reg=0.001):\n",
        "    #weights frozen for base\n",
        "    cnn_base = EfficientNetV2S(include_top=False, weights='imagenet', pooling='avg')\n",
        "    cnn_base.trainable = False\n",
        "    video_input = layers.Input(shape=(sequence_length, 224, 224, 3))\n",
        "    adjacency_input = layers.Input(shape=(num_nodes, num_nodes))\n",
        "    cnn_out = TimeDistributed(cnn_base)(video_input)\n",
        "    cnn_out = Dropout(dropout_rate)(cnn_out)\n",
        "    adjacency_input_reshaped = Reshape((num_nodes, num_nodes))(adjacency_input)\n",
        "\n",
        "\n",
        "    gnn_out = GCNConv(64, activation='relu', kernel_regularizer=l2(l2_reg))([cnn_out, adjacency_input_reshaped])\n",
        "    gnn_out = GlobalAveragePooling1D()(gnn_out)\n",
        "\n",
        "    output = Dense(sequence_length * num_nodes * num_classes, activation='softmax', kernel_regularizer=l2(l2_reg))(gnn_out)  # Reduced L2 regularization\n",
        "    output = Reshape((sequence_length, num_nodes, num_classes))(output)\n",
        "    output = layers.Permute((2, 1, 3))(output)  # Swap dimensions to match label shape\n",
        "\n",
        "    model = models.Model(inputs=[video_input, adjacency_input], outputs=output)\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_sequence_model(sequence_length=16, num_nodes=16, num_features=1280, num_classes=5)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8FJGjjDUCZZ"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs= 200,\n",
        "    validation_data=validation_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9x__JE0eGDgV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}