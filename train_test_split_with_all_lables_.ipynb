{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlPGjD27Fbuv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "directory = '/content/drive/My Drive/batches matches full'\n",
        "files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pkl')]\n",
        "\n",
        "#group files by video ID and keep all batches from the same video in order to preserve temporal nature of video\n",
        "video_files = {}\n",
        "for f in files:\n",
        "    match = re.search(r'P(\\d+)_batch_(\\d+)', f)\n",
        "    if match:\n",
        "        video_id, batch_number = int(match.group(1)), int(match.group(2))\n",
        "        if video_id not in video_files:\n",
        "            video_files[video_id] = []\n",
        "        video_files[video_id].append((batch_number, f))\n",
        "\n",
        "for video_id in video_files.keys():\n",
        "    video_files[video_id].sort(key=lambda x: x[0])\n",
        "    video_files[video_id] = [f for _, f in video_files[video_id]]\n",
        "\n",
        "sorted_video_ids = sorted(video_files.keys())\n",
        "train_video_ids = sorted_video_ids[:20]  #first 20 videos for training\n",
        "test_video_ids = sorted_video_ids[-5:]  #last 5 videos for testing\n",
        "\n",
        "train_files = [file for vid in train_video_ids for file in video_files[vid]]\n",
        "test_files = [file for vid in test_video_ids for file in video_files[vid]]\n",
        "\n",
        "def load_sequences_and_labels(file_list):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for file_path in file_list:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            sequence_data = pickle.load(file)\n",
        "            frames = [item[0] for item in sequence_data]\n",
        "            sequence_labels = [item[1] for item in sequence_data]\n",
        "            sequences.append(frames)\n",
        "            labels.append(sequence_labels)\n",
        "    return sequences, labels\n",
        "\n",
        "X_train, Y_train = load_sequences_and_labels(train_files)\n",
        "X_test, Y_test = load_sequences_and_labels(test_files)"
      ],
      "metadata": {
        "id": "lysDoQh9F2LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding the labels as numbers manually\n",
        "label_mapping = {'Injection': 0, 'Optimising_Position': 1, 'Polypectomy': 2, 'Inspecting_Resection':3,'Other':4}\n",
        "\n",
        "Y_train_int = [[label_mapping[label] for label in seq] for seq in Y_train]\n",
        "Y_test_int = [[label_mapping[label] for label in seq] for seq in Y_test]"
      ],
      "metadata": {
        "id": "jSXo7tlLF2tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sequence generator is used to create sequences in order to capture temporal relationships that will be captured by LSTMs\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "class SequentialDataGenerator(Sequence):\n",
        "    def __init__(self, X, Y_int, batch_size=16, num_classes=None, max_sequence_length=None):\n",
        "        self.X = X #sequences\n",
        "        self.Y_int = Y_int  #integer-encoded labels\n",
        "        self.batch_size = batch_size  # Batch size\n",
        "        self.num_classes = num_classes  #total number of classes\n",
        "        self.max_sequence_length = max_sequence_length or self._max_length()  #calculating max sequence length\n",
        "        self.indexes = np.arange(len(self.X))  #indices of the sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        batch_X = [self.X[k] for k in indexes]\n",
        "        batch_Y_int = [self.Y_int[k] for k in indexes]\n",
        "\n",
        "        #the last frames from each video may not add up to 16 (sequence length) so to ensure equal length they are padded with the label 'Other'\n",
        "        X_temp_padded = self._pad_sequences(batch_X, self.max_sequence_length)\n",
        "        Y_temp_encoded = [to_categorical(y, num_classes=self.num_classes) for y in batch_Y_int]\n",
        "        Y_temp_padded = self._pad_sequences(Y_temp_encoded, self.max_sequence_length, pad_val=[0 if i != label_mapping['Other'] else 1 for i in range(self.num_classes)])\n",
        "\n",
        "        return np.array(X_temp_padded), np.array(Y_temp_padded)\n",
        "\n",
        "    #the order of the epochs are not shuffled in order to maintain the temporal nature of the videos\n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "\n",
        "    def _max_length(self):\n",
        "        return max(len(seq) for seq in self.X)\n",
        "\n",
        "    def _pad_sequences(self, sequences, max_seq_length, pad_val=0):\n",
        "        padded_sequences = []\n",
        "        for seq in sequences:\n",
        "            seq = np.array(seq)\n",
        "            current_length = len(seq)\n",
        "            pad_size = max_seq_length - current_length\n",
        "\n",
        "            if pad_size > 0:\n",
        "                if isinstance(pad_val, list):\n",
        "                    pad_array = np.array([pad_val for _ in range(pad_size)])\n",
        "                    padded_seq = np.concatenate((seq, pad_array), axis=0)\n",
        "                else:\n",
        "                    pad_shape = ((0, pad_size),) + ((0, 0),) * (seq.ndim - 1)\n",
        "                    padded_seq = np.pad(seq, pad_shape, mode='constant', constant_values=pad_val)\n",
        "            else:\n",
        "                padded_seq = seq\n",
        "\n",
        "            padded_sequences.append(padded_seq)\n",
        "        return padded_sequences"
      ],
      "metadata": {
        "id": "dsrNk-Z-F4pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "\n",
        "train_generator = SequentialDataGenerator(X_train, Y_train_int, batch_size=16, num_classes=5)\n",
        "validation_generator = SequentialDataGenerator(X_test, Y_test_int, batch_size=16, num_classes=5)\n",
        "\n",
        "\n",
        "x_sample, y_sample = next(iter(train_generator))\n",
        "print(\"X_sample shape:\", x_sample.shape)\n",
        "print(\"Y_sample shape:\", y_sample.shape)"
      ],
      "metadata": {
        "id": "MxGPqHGnF6sx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}