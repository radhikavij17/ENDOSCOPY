{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "PR3x-DYz7_pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbmF7OZq72gU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#same process as with all labels here except use your own directory path\n",
        "\n",
        "directory = '/content/drive/My Drive/batches matches full'\n",
        "files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pkl')]\n",
        "\n",
        "\n",
        "video_files = {}\n",
        "for f in files:\n",
        "    match = re.search(r'P(\\d+)_batch_(\\d+)', f)\n",
        "    if match:\n",
        "        video_id, batch_number = int(match.group(1)), int(match.group(2))\n",
        "        if video_id not in video_files:\n",
        "            video_files[video_id] = []\n",
        "        video_files[video_id].append((batch_number, f))\n",
        "\n",
        "for video_id in video_files.keys():\n",
        "    video_files[video_id].sort(key=lambda x: x[0])\n",
        "    video_files[video_id] = [f for _, f in video_files[video_id]]\n",
        "\n",
        "sorted_video_ids = sorted(video_files.keys())\n",
        "train_video_ids = sorted_video_ids[:20]\n",
        "test_video_ids = sorted_video_ids[-5:]\n",
        "\n",
        "train_files = [file for vid in train_video_ids for file in video_files[vid]]\n",
        "test_files = [file for vid in test_video_ids for file in video_files[vid]]\n",
        "\n",
        "def load_sequences_and_labels(file_list):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for file_path in file_list:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            sequence_data = pickle.load(file)\n",
        "            frames = [item[0] for item in sequence_data]\n",
        "            sequence_labels = [item[1] for item in sequence_data]\n",
        "            sequences.append(frames)\n",
        "            labels.append(sequence_labels)\n",
        "    return sequences, labels\n",
        "\n",
        "X_train, Y_train = load_sequences_and_labels(train_files)\n",
        "X_test, Y_test = load_sequences_and_labels(test_files)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {'Injection': 0, 'Optimising_Position': 1, 'Polypectomy': 2, 'Inspecting_Resection':3,'Other':4}\n",
        "\n",
        "#filtering out frames and labels where label is 'Other'\n",
        "def remove_label_other(X, Y, label_to_remove='Other'):\n",
        "    filtered_X = []\n",
        "    filtered_Y = []\n",
        "    for x_seq, y_seq in zip(X, Y):\n",
        "        filtered_seq = [(frame, label) for frame, label in zip(x_seq, y_seq) if label != label_to_remove]\n",
        "        if filtered_seq:\n",
        "            filtered_frames, filtered_labels = zip(*filtered_seq)\n",
        "            filtered_X.append(list(filtered_frames))\n",
        "            filtered_Y.append([label for label in filtered_labels])\n",
        "    return filtered_X, filtered_Y\n",
        "\n",
        "X_train_filtered, Y_train_filtered = remove_label_other(X_train, Y_train, 'Other')\n",
        "X_test_filtered, Y_test_filtered = remove_label_other(X_test, Y_test, 'Other')\n",
        "\n",
        "Y_train_int_filtered = [[label_mapping[label] for label in seq] for seq in Y_train_filtered]\n",
        "Y_test_int_filtered = [[label_mapping[label] for label in seq] for seq in Y_test_filtered]\n"
      ],
      "metadata": {
        "id": "AOMmggZbD8Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import mode\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "\n",
        "class SequentialDataGenerator(Sequence):\n",
        "    def __init__(self, X, Y_int, batch_size=16, num_classes=None, max_sequence_length=None):\n",
        "        self.X = X\n",
        "        self.Y_int = Y_int\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.max_sequence_length = max_sequence_length or self._max_length()\n",
        "        self.indexes = np.arange(len(self.X))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_X = [self.X[k] for k in indexes]\n",
        "        batch_Y_int = [self.Y_int[k] for k in indexes]\n",
        "\n",
        "        X_temp_padded = self._pad_sequences(batch_X, self.max_sequence_length)\n",
        "        Y_temp_encoded = [to_categorical(y, num_classes=self.num_classes) for y in batch_Y_int]\n",
        "        Y_temp_padded = self._pad_sequences(Y_temp_encoded, self.max_sequence_length, pad_val='mode')  # Indicating mode padding with 'mode'\n",
        "\n",
        "        return np.array(X_temp_padded), np.array(Y_temp_padded)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "\n",
        "    def _max_length(self):\n",
        "        return max(len(seq) for seq in self.X)\n",
        "#here because the 'Other' label is removed, instead of padding with 'Other', we will be padding with the mode of that sequence if the sequence is shorter than 16\n",
        "    def _pad_sequences(self, sequences, max_seq_length, pad_val=0):\n",
        "        padded_sequences = []\n",
        "        for seq in sequences:\n",
        "            seq = np.array(seq)\n",
        "            current_length = seq.shape[0]\n",
        "            pad_size = max_seq_length - current_length\n",
        "\n",
        "            if pad_size > 0:\n",
        "                if isinstance(pad_val, str) and pad_val == 'mode':\n",
        "                    if seq.ndim == 2 and seq.size > 0:\n",
        "                        int_labels = np.argmax(seq, axis=1)\n",
        "                        if int_labels.size > 0:\n",
        "                            try:\n",
        "                                mode_result = mode(int_labels)\n",
        "                                most_common_label_index = mode_result.mode[0]\n",
        "                            except IndexError:\n",
        "                                most_common_label_index = 0\n",
        "                            mode_label_one_hot = to_categorical(most_common_label_index, num_classes=self.num_classes)\n",
        "                            pad_array = np.tile(mode_label_one_hot, (pad_size, 1))\n",
        "                        else:\n",
        "                            pad_array = np.zeros((pad_size, self.num_classes))\n",
        "                    else:\n",
        "                        pad_array = np.zeros((pad_size, self.num_classes))\n",
        "                else:\n",
        "                    if isinstance(pad_val, list) and len(pad_val) == seq.shape[-1]:\n",
        "                        pad_array = np.array([pad_val] * pad_size)\n",
        "                    else:\n",
        "                        pad_array = np.zeros((pad_size,) + seq.shape[1:], dtype=seq.dtype)\n",
        "\n",
        "                padded_seq = np.concatenate((seq, pad_array), axis=0)\n",
        "            else:\n",
        "                padded_seq = seq\n",
        "\n",
        "            padded_sequences.append(padded_seq)\n",
        "        return padded_sequences"
      ],
      "metadata": {
        "id": "5zhH18EP8BMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4\n",
        "train_generator = SequentialDataGenerator(X_train_filtered, Y_train_int_filtered, batch_size=16, num_classes=len(label_mapping))\n",
        "test_generator = SequentialDataGenerator(X_test_filtered, Y_test_int_filtered, batch_size=16, num_classes=len(label_mapping))\n",
        "\n",
        "\n",
        "x_sample, y_sample = next(iter(train_generator))\n",
        "print(\"X_sample shape:\", x_sample.shape)\n",
        "print(\"Y_sample shape:\", y_sample.shape)"
      ],
      "metadata": {
        "id": "lgGP7TIBviOb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}