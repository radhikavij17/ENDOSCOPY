{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Embedding, Dense, Dropout, TimeDistributed, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import EfficientNetV2S\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, sequence_length, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(sequence_length, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],\n",
        "                                     np.arange(d_model)[np.newaxis, :],\n",
        "                                     d_model)\n",
        "\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        sines = np.sin(angle_rads[:, 0::2])\n",
        "        cosines = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        angle_rads[:, 0::2] = sines\n",
        "        angle_rads[:, 1::2] = cosines\n",
        "\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.mha = MultiHeadAttention(key_dim=d_model, num_heads=num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [Dense(dff, activation='relu'), Dense(d_model)]\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        attn_output = self.mha(x, x, x)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "        return out2\n",
        "\n",
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.enc_layers = [TransformerEncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = Dropout(rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        x = self.dropout(x, training=training)\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training)\n",
        "        return x\n",
        "\n",
        "def create_model_with_transformer(sequence_length, frame_shape, num_classes, num_layers=2, d_model=256, num_heads=4, dff=1024, rate=0.1):\n",
        "    video_input = Input(shape=(sequence_length,) + frame_shape)\n",
        "\n",
        "    base_model = EfficientNetV2S(weights='imagenet', include_top=False, input_shape=frame_shape)\n",
        "    base_model.trainable = False  #frozen weights\n",
        "\n",
        "    encoded_frames = TimeDistributed(base_model)(video_input)\n",
        "    encoded_frames = TimeDistributed(GlobalAveragePooling2D())(encoded_frames)\n",
        "\n",
        "    encoded_frames = TimeDistributed(Dense(d_model))(encoded_frames)\n",
        "\n",
        "    encoded_frames = PositionalEncoding(sequence_length, d_model)(encoded_frames)\n",
        "\n",
        "    transformer_encoder = TransformerEncoder(num_layers, d_model, num_heads, dff, rate)\n",
        "    encoded_sequence = transformer_encoder(encoded_frames)\n",
        "    outputs = TimeDistributed(Dense(num_classes, activation='softmax'))(encoded_sequence)\n",
        "\n",
        "    model = Model(inputs=video_input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_model_with_transformer(sequence_length=16, frame_shape=(224, 224, 3), num_classes=5)\n",
        "model.compile(optimizer=Adam(learning_rate=0.00006), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "lYgVH7tP8Nsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs= 200,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "#then save the model, run predicitons, error analysis etc."
      ],
      "metadata": {
        "id": "laPYjGwM8RPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}